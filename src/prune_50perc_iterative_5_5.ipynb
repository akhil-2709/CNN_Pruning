{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12783,"status":"ok","timestamp":1650238946384,"user":{"displayName":"Akhil Reddy Anthireddy","userId":"13059027232826718756"},"user_tz":240},"id":"6XIGgKCOXjij","outputId":"3e001e91-4956-4f4e-cc8f-f79b9fb646ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","import warnings\n","warnings.filterwarnings('ignore')\n","import sys\n","sys.path.append('/content/drive/My Drive/cs532_project2')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5536,"status":"ok","timestamp":1650238951914,"user":{"displayName":"Akhil Reddy Anthireddy","userId":"13059027232826718756"},"user_tz":240},"id":"WZ-7SZ-WYujO"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":183,"status":"ok","timestamp":1650238952091,"user":{"displayName":"Akhil Reddy Anthireddy","userId":"13059027232826718756"},"user_tz":240},"id":"ruL494EVY0HD"},"outputs":[],"source":["def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(\n","        in_planes,\n","        out_planes,\n","        kernel_size=3,\n","        stride=stride,\n","        padding=dilation,\n","        groups=groups,\n","        bias=False,\n","        dilation=dilation,\n","    )\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(\n","        self,\n","        inplanes,\n","        planes,\n","        stride=1,\n","        downsample=None,\n","        groups=1,\n","        base_width=64,\n","        dilation=1,\n","        norm_layer=None,\n","    ):\n","        super(BasicBlock, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n","        if dilation > 1:\n","            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(\n","        self,\n","        inplanes,\n","        planes,\n","        stride=1,\n","        downsample=None,\n","        groups=1,\n","        base_width=64,\n","        dilation=1,\n","        norm_layer=None,\n","    ):\n","        super(Bottleneck, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        width = int(planes * (base_width / 64.0)) * groups\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv1x1(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","        self.bn2 = norm_layer(width)\n","        self.conv3 = conv1x1(width, planes * self.expansion)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(\n","        self,\n","        block,\n","        layers,\n","        num_classes=10,\n","        zero_init_residual=False,\n","        groups=1,\n","        width_per_group=64,\n","        replace_stride_with_dilation=None,\n","        norm_layer=None,\n","    ):\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n","\n","        self.inplanes = 64\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            # each element in the tuple indicates if we should replace\n","            # the 2x2 stride with a dilated convolution instead\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\n","                \"replace_stride_with_dilation should be None \"\n","                \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation)\n","            )\n","        self.groups = groups\n","        self.base_width = width_per_group\n","\n","        # CIFAR10: kernel_size 7 -> 3, stride 2 -> 1, padding 3->1\n","        self.conv1 = nn.Conv2d(\n","            3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False\n","        )\n","        # END\n","\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(\n","            block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0]\n","        )\n","        self.layer3 = self._make_layer(\n","            block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1]\n","        )\n","        self.layer4 = self._make_layer(\n","            block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2]\n","        )\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(\n","            block(\n","                self.inplanes,\n","                planes,\n","                stride,\n","                downsample,\n","                self.groups,\n","                self.base_width,\n","                previous_dilation,\n","                norm_layer,\n","            )\n","        )\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(\n","                block(\n","                    self.inplanes,\n","                    planes,\n","                    groups=self.groups,\n","                    base_width=self.base_width,\n","                    dilation=self.dilation,\n","                    norm_layer=norm_layer,\n","                )\n","            )\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = x.reshape(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","\n","def _resnet(arch, block, layers, pretrained, progress, device, **kwargs):\n","    model = ResNet(block, layers, **kwargs)\n","    if pretrained:\n","        state_dict = torch.load('/content/drive/My Drive/cs532_project2/resnet18.pt')\n","        # state_dict = torch.load(\n","        #     script_dir + \"/state_dicts/\" + arch + \".pt\", map_location=device\n","        # )\n","        model.load_state_dict(state_dict)\n","    return model\n","\n","\n","def resnet18(pretrained=False, progress=True, device=\"cpu\", **kwargs):\n","    \"\"\"Constructs a ResNet-18 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet(\n","        \"resnet18\", BasicBlock, [2, 2, 2, 2], pretrained, progress, device, **kwargs\n","    )\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9997,"status":"ok","timestamp":1650238962209,"user":{"displayName":"Akhil Reddy Anthireddy","userId":"13059027232826718756"},"user_tz":240},"id":"uSYVuu6gZHV1","outputId":"a638d0b3-21b9-42a0-cd19-9687cc30eaee"},"outputs":[{"data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["###Verify if gpu resource available for running the models and load the base pre-trained resnet-18 model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = resnet18(pretrained=True)\n","model.load_state_dict(torch.load('/content/drive/My Drive/cs532_project2/resnet18.pt'))\n","model.to(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["59663be5028c4e65ae5a0d5fad90979c","3cb364e8a0664aa9866152d70547295a","2e8fbfb292744b82b3d6ca6837d16e82","2dd1d68ae2f14a5cab73f24ec3d0432a","2b205028157a4bdfa3793986c664bc41","79a1db2c0f1046f6bf4505b6b5643612","702d5bf86ccf4a7488bec7128851d1f0","5d900d7d5e5641839e68781ca50df13a","c848806b821d4f31902a41b325f9209b","b2ad091de2ac41819417efebdec2b2ce","3b894f4bb158405189dcba5fd6243277"]},"executionInfo":{"elapsed":9746,"status":"ok","timestamp":1650238971951,"user":{"displayName":"Akhil Reddy Anthireddy","userId":"13059027232826718756"},"user_tz":240},"id":"JlSKDk67gJmH","outputId":"c5de4348-8569-40d9-8945-951f4fed611a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59663be5028c4e65ae5a0d5fad90979c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ../../data/cifar-10-python.tar.gz to ../../data/\n"]}],"source":["from torchvision import transforms as T\n","#Configuration of the device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#Values of hyper-parameters\n","num_epochs = 5\n","learning_rate = 0.0005\n","\n","#Mean and standard deviation of the data calculated in order to normalize the data\n","mean = (0.4914, 0.4822, 0.4465)\n","std = (0.2471, 0.2435, 0.2616)\n","\n","transform = T.Compose(\n","            [\n","                T.ToTensor(),\n","                T.Normalize(mean, std),\n","            ]\n","        )\n","\n","# Obtain the train and test datasets from CIFAR-10 dataset\n","\n","train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n","                                             train=True, \n","                                             transform=transform,\n","                                             download=True)\n","\n","test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n","                                            train=False, \n","                                            transform=transform)\n","\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=100, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=100, \n","                                          shuffle=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2297,"status":"ok","timestamp":1650238974240,"user":{"displayName":"Akhil Reddy Anthireddy","userId":"13059027232826718756"},"user_tz":240},"id":"WtkWiM_bjEHi"},"outputs":[],"source":["### Calculating the accuracy for the base model before pruning\n","num_correct = 0\n","num_samples = 0\n","before_prune_acc = 0\n","model.eval()\n","with torch.no_grad():\n","    for x, y in test_loader:\n","        x = x.to(device=device)  # move to device, e.g. GPU\n","        y = y.to(device=device)\n","        scores = model(x)\n","        _, preds = scores.max(1)\n","        num_correct += (preds == y).sum()\n","        num_samples += preds.size(0)\n","    before_prune_acc = float(num_correct) / num_samples\n","    # print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * before_prune_acc))"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650238974240,"user":{"displayName":"Akhil Reddy Anthireddy","userId":"13059027232826718756"},"user_tz":240},"id":"1u3OZQbmZvrs"},"outputs":[],"source":["import torch.nn.utils.prune as prune\n","import copy\n","\n","### Storing all the parameters from the model for pruning\n","parameters_to_prune = (\n","\n","    (model.conv1, 'weight'),\n","\n","    (model.layer1[0].conv1, 'weight'),\n","    (model.layer1[0].conv2, 'weight'),\n","    (model.layer1[1].conv1, 'weight'),\n","    (model.layer1[1].conv2, 'weight'),\n","\n","    (model.layer2[0].conv1, 'weight'),\n","    (model.layer2[0].conv2, 'weight'),\n","    (model.layer2[1].conv1, 'weight'),\n","    (model.layer2[1].conv2, 'weight'),\n","\n","    (model.layer3[0].conv1, 'weight'),\n","    (model.layer3[0].conv2, 'weight'),\n","    (model.layer3[1].conv1, 'weight'),\n","    (model.layer3[1].conv2, 'weight'),\n","\n","    (model.layer4[0].conv1, 'weight'),\n","    (model.layer4[0].conv2, 'weight'),\n","    (model.layer4[1].conv1, 'weight'),\n","    (model.layer4[1].conv2, 'weight'),\n","\n","    (model.fc, 'weight'),\n","\n",")    \n","\n","### Storing all the modules so that the original weights that wwill be pruned and not required will be deleted\n","modules = []\n","for name, module in model.named_modules():\n","    if \"conv\" in name or \"fc\" in name:\n","        modules.append(module)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":548667,"status":"ok","timestamp":1650239522903,"user":{"displayName":"Akhil Reddy Anthireddy","userId":"13059027232826718756"},"user_tz":240},"id":"S6d-IOvMbkeT","outputId":"fc708bde-6760-4bc6-c0ef-3566e174888f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration - 0 \n","\n","Batch Index : 100 Loss : 0.0214 Time : 3.760 seconds \n","Batch Index : 200 Loss : 0.0247 Time : 3.672 seconds \n","Batch Index : 300 Loss : 0.0459 Time : 3.675 seconds \n","Batch Index : 400 Loss : 0.1114 Time : 3.682 seconds \n","Batch Index : 500 Loss : 0.0088 Time : 3.697 seconds \n","Epoch : 0, Test Accuracy : 90.520 %\n","Accuracy Drop : 2.550 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0240 Time : 3.724 seconds \n","Batch Index : 200 Loss : 0.0548 Time : 3.728 seconds \n","Batch Index : 300 Loss : 0.0367 Time : 3.736 seconds \n","Batch Index : 400 Loss : 0.0671 Time : 3.744 seconds \n","Batch Index : 500 Loss : 0.0413 Time : 3.745 seconds \n","Epoch : 1, Test Accuracy : 92.750 %\n","Accuracy Drop : 0.320 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0260 Time : 3.757 seconds \n","Batch Index : 200 Loss : 0.0737 Time : 3.775 seconds \n","Batch Index : 300 Loss : 0.0242 Time : 3.777 seconds \n","Batch Index : 400 Loss : 0.0326 Time : 3.791 seconds \n","Batch Index : 500 Loss : 0.0269 Time : 3.795 seconds \n","Epoch : 2, Test Accuracy : 93.000 %\n","Accuracy Drop : 0.070 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0297 Time : 3.815 seconds \n","Batch Index : 200 Loss : 0.0183 Time : 3.813 seconds \n","Batch Index : 300 Loss : 0.0267 Time : 3.824 seconds \n","Batch Index : 400 Loss : 0.0194 Time : 3.837 seconds \n","Batch Index : 500 Loss : 0.0308 Time : 3.842 seconds \n","Epoch : 3, Test Accuracy : 92.950 %\n","Accuracy Drop : 0.120 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0146 Time : 3.849 seconds \n","Batch Index : 200 Loss : 0.0178 Time : 3.857 seconds \n","Batch Index : 300 Loss : 0.0195 Time : 3.859 seconds \n","Batch Index : 400 Loss : 0.0172 Time : 3.867 seconds \n","Batch Index : 500 Loss : 0.0161 Time : 3.883 seconds \n","Epoch : 4, Test Accuracy : 92.920 %\n","Accuracy Drop : 0.150 %\n","--------------------------------------------------------------\n","\n","\n","\n","Iteration - 1 \n","\n","Batch Index : 100 Loss : 0.0164 Time : 3.884 seconds \n","Batch Index : 200 Loss : 0.0208 Time : 3.881 seconds \n","Batch Index : 300 Loss : 0.0160 Time : 3.890 seconds \n","Batch Index : 400 Loss : 0.0145 Time : 3.898 seconds \n","Batch Index : 500 Loss : 0.0223 Time : 3.908 seconds \n","Epoch : 0, Test Accuracy : 92.830 %\n","Accuracy Drop : 0.240 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0116 Time : 3.910 seconds \n","Batch Index : 200 Loss : 0.0183 Time : 3.919 seconds \n","Batch Index : 300 Loss : 0.0179 Time : 3.921 seconds \n","Batch Index : 400 Loss : 0.0135 Time : 3.927 seconds \n","Batch Index : 500 Loss : 0.0144 Time : 3.935 seconds \n","Epoch : 1, Test Accuracy : 92.940 %\n","Accuracy Drop : 0.130 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0161 Time : 3.949 seconds \n","Batch Index : 200 Loss : 0.0140 Time : 3.945 seconds \n","Batch Index : 300 Loss : 0.0112 Time : 3.958 seconds \n","Batch Index : 400 Loss : 0.0290 Time : 3.959 seconds \n","Batch Index : 500 Loss : 0.0170 Time : 3.951 seconds \n","Epoch : 2, Test Accuracy : 92.950 %\n","Accuracy Drop : 0.120 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0132 Time : 3.954 seconds \n","Batch Index : 200 Loss : 0.0132 Time : 3.958 seconds \n","Batch Index : 300 Loss : 0.0187 Time : 3.980 seconds \n","Batch Index : 400 Loss : 0.0109 Time : 3.985 seconds \n","Batch Index : 500 Loss : 0.0117 Time : 3.973 seconds \n","Epoch : 3, Test Accuracy : 93.070 %\n","Accuracy Drop : 0.000 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0093 Time : 3.996 seconds \n","Batch Index : 200 Loss : 0.0113 Time : 4.002 seconds \n","Batch Index : 300 Loss : 0.0098 Time : 3.993 seconds \n","Batch Index : 400 Loss : 0.0117 Time : 4.001 seconds \n","Batch Index : 500 Loss : 0.0115 Time : 3.989 seconds \n","Epoch : 4, Test Accuracy : 92.980 %\n","Accuracy Drop : 0.090 %\n","--------------------------------------------------------------\n","\n","\n","\n","Iteration - 2 \n","\n","Batch Index : 100 Loss : 0.0185 Time : 4.009 seconds \n","Batch Index : 200 Loss : 0.0166 Time : 4.020 seconds \n","Batch Index : 300 Loss : 0.0082 Time : 4.010 seconds \n","Batch Index : 400 Loss : 0.0124 Time : 4.009 seconds \n","Batch Index : 500 Loss : 0.0111 Time : 4.016 seconds \n","Epoch : 0, Test Accuracy : 92.830 %\n","Accuracy Drop : 0.240 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0134 Time : 4.006 seconds \n","Batch Index : 200 Loss : 0.0097 Time : 3.999 seconds \n","Batch Index : 300 Loss : 0.0099 Time : 4.009 seconds \n","Batch Index : 400 Loss : 0.0139 Time : 4.004 seconds \n","Batch Index : 500 Loss : 0.0107 Time : 4.010 seconds \n","Epoch : 1, Test Accuracy : 92.890 %\n","Accuracy Drop : 0.180 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0168 Time : 4.010 seconds \n","Batch Index : 200 Loss : 0.0102 Time : 4.002 seconds \n","Batch Index : 300 Loss : 0.0117 Time : 4.010 seconds \n","Batch Index : 400 Loss : 0.0066 Time : 4.011 seconds \n","Batch Index : 500 Loss : 0.0281 Time : 4.004 seconds \n","Epoch : 2, Test Accuracy : 93.040 %\n","Accuracy Drop : 0.030 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0085 Time : 4.006 seconds \n","Batch Index : 200 Loss : 0.0106 Time : 4.003 seconds \n","Batch Index : 300 Loss : 0.0257 Time : 4.007 seconds \n","Batch Index : 400 Loss : 0.0134 Time : 3.996 seconds \n","Batch Index : 500 Loss : 0.0160 Time : 3.999 seconds \n","Epoch : 3, Test Accuracy : 93.030 %\n","Accuracy Drop : 0.040 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0154 Time : 4.018 seconds \n","Batch Index : 200 Loss : 0.0081 Time : 4.016 seconds \n","Batch Index : 300 Loss : 0.0088 Time : 4.000 seconds \n","Batch Index : 400 Loss : 0.0079 Time : 4.003 seconds \n","Batch Index : 500 Loss : 0.0111 Time : 4.016 seconds \n","Epoch : 4, Test Accuracy : 92.940 %\n","Accuracy Drop : 0.130 %\n","--------------------------------------------------------------\n","\n","\n","\n","Iteration - 3 \n","\n","Batch Index : 100 Loss : 0.0096 Time : 4.002 seconds \n","Batch Index : 200 Loss : 0.0104 Time : 4.011 seconds \n","Batch Index : 300 Loss : 0.0064 Time : 3.996 seconds \n","Batch Index : 400 Loss : 0.0122 Time : 3.996 seconds \n","Batch Index : 500 Loss : 0.0087 Time : 3.996 seconds \n","Epoch : 0, Test Accuracy : 92.880 %\n","Accuracy Drop : 0.190 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0128 Time : 4.006 seconds \n","Batch Index : 200 Loss : 0.0095 Time : 3.992 seconds \n","Batch Index : 300 Loss : 0.0053 Time : 4.002 seconds \n","Batch Index : 400 Loss : 0.0061 Time : 4.000 seconds \n","Batch Index : 500 Loss : 0.0079 Time : 3.993 seconds \n","Epoch : 1, Test Accuracy : 92.990 %\n","Accuracy Drop : 0.080 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0067 Time : 3.994 seconds \n","Batch Index : 200 Loss : 0.0120 Time : 3.998 seconds \n","Batch Index : 300 Loss : 0.0088 Time : 3.994 seconds \n","Batch Index : 400 Loss : 0.0049 Time : 3.986 seconds \n","Batch Index : 500 Loss : 0.0050 Time : 3.990 seconds \n","Epoch : 2, Test Accuracy : 92.900 %\n","Accuracy Drop : 0.170 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0140 Time : 3.996 seconds \n","Batch Index : 200 Loss : 0.0068 Time : 3.984 seconds \n","Batch Index : 300 Loss : 0.0101 Time : 4.004 seconds \n","Batch Index : 400 Loss : 0.0069 Time : 3.998 seconds \n","Batch Index : 500 Loss : 0.0060 Time : 3.990 seconds \n","Epoch : 3, Test Accuracy : 92.910 %\n","Accuracy Drop : 0.160 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0054 Time : 4.008 seconds \n","Batch Index : 200 Loss : 0.0063 Time : 3.998 seconds \n","Batch Index : 300 Loss : 0.0071 Time : 3.996 seconds \n","Batch Index : 400 Loss : 0.0071 Time : 3.994 seconds \n","Batch Index : 500 Loss : 0.0053 Time : 3.996 seconds \n","Epoch : 4, Test Accuracy : 93.000 %\n","Accuracy Drop : 0.070 %\n","--------------------------------------------------------------\n","\n","\n","\n","Iteration - 4 \n","\n","Batch Index : 100 Loss : 0.0061 Time : 3.984 seconds \n","Batch Index : 200 Loss : 0.0045 Time : 3.998 seconds \n","Batch Index : 300 Loss : 0.0065 Time : 3.987 seconds \n","Batch Index : 400 Loss : 0.0065 Time : 3.986 seconds \n","Batch Index : 500 Loss : 0.0063 Time : 3.996 seconds \n","Epoch : 0, Test Accuracy : 93.040 %\n","Accuracy Drop : 0.030 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0058 Time : 4.022 seconds \n","Batch Index : 200 Loss : 0.0082 Time : 4.001 seconds \n","Batch Index : 300 Loss : 0.0040 Time : 3.994 seconds \n","Batch Index : 400 Loss : 0.0051 Time : 4.015 seconds \n","Batch Index : 500 Loss : 0.0063 Time : 3.992 seconds \n","Epoch : 1, Test Accuracy : 92.980 %\n","Accuracy Drop : 0.090 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0073 Time : 3.997 seconds \n","Batch Index : 200 Loss : 0.0040 Time : 4.000 seconds \n","Batch Index : 300 Loss : 0.0091 Time : 3.999 seconds \n","Batch Index : 400 Loss : 0.0043 Time : 4.006 seconds \n","Batch Index : 500 Loss : 0.0047 Time : 3.995 seconds \n","Epoch : 2, Test Accuracy : 92.980 %\n","Accuracy Drop : 0.090 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0093 Time : 3.989 seconds \n","Batch Index : 200 Loss : 0.0084 Time : 3.998 seconds \n","Batch Index : 300 Loss : 0.0094 Time : 3.999 seconds \n","Batch Index : 400 Loss : 0.0047 Time : 4.008 seconds \n","Batch Index : 500 Loss : 0.0046 Time : 4.012 seconds \n","Epoch : 3, Test Accuracy : 92.930 %\n","Accuracy Drop : 0.140 %\n","--------------------------------------------------------------\n","Batch Index : 100 Loss : 0.0039 Time : 3.995 seconds \n","Batch Index : 200 Loss : 0.0050 Time : 4.001 seconds \n","Batch Index : 300 Loss : 0.0048 Time : 4.004 seconds \n","Batch Index : 400 Loss : 0.0052 Time : 4.006 seconds \n","Batch Index : 500 Loss : 0.0073 Time : 4.006 seconds \n","Epoch : 4, Test Accuracy : 92.890 %\n","Accuracy Drop : 0.180 %\n","--------------------------------------------------------------\n","\n","\n","\n"]}],"source":["import numpy as np\n","import time as time\n","\n","iterations = 5\n","\n","### Pruning and training model for 5 iterations to achieve 50% sparsity in total\n","for itr in range(iterations):\n","  print(\"Iteration - %d \\n\"%itr)\n","\n","   ### Pruning function that will prune so as to achieve 50% sparsity after 5 iterations\n","  prune.global_unstructured(\n","    parameters_to_prune,\n","    pruning_method=prune.L1Unstructured,\n","    amount=0.1295,\n","  )\n","\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.7)\n","  scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 200], gamma=0.1)\n","\n","  for mod in modules:\n","      prune.remove(mod, 'weight')\n","\n","  # def update_lr(optimizer, lr):    \n","  #     for param_group in optimizer.param_groups:\n","  #         param_group['lr'] = lr\n","\n","\n","  # total_step = len(train_loader)\n","  # curr_lr = learning_rate\n","\n","  ### Model Training\n","  for epoch in range(num_epochs):\n","    # losses = []\n","    #scheduler.step()\n","    start = time.time()\n","\n","    for i, (inputs, targets) in enumerate(train_loader):\n","        inputs = inputs.to(device)\n","        targets = targets.to(device)\n","\n","        ## Forward Propogation and Loss calculation\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","\n","        ## Backward Propogation and Optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # losses.append(loss.item())\n","\n","        end = time.time()\n","      \n","        if (i+1) % 100 == 0:\n","          print('Batch Index : %d Loss : %.4f Time : %.3f seconds ' % (\n","              i+1,\n","              loss.item(), \n","              # np.mean(losses), \n","              end - start))\n","    \n","          start = time.time()\n","          # if (i+1) % 100 == 0:\n","          #     print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n","          #            .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n"," \n","    ## Calculating the accuracy on the test set  \n","    num_correct = 0\n","    num_samples = 0\n","    model.eval()\n","    with torch.no_grad():\n","        for x, y in test_loader:\n","            x = x.to(device=device)  # move to device, e.g. GPU\n","            y = y.to(device=device)\n","            scores = model(x)\n","            _, preds = scores.max(1)\n","            num_correct += (preds == y).sum()\n","            num_samples += preds.size(0)\n","        acc = float(num_correct) / num_samples\n","      \n","        print('Epoch : %d, Test Accuracy : %.3f %%' % (epoch, 100.*acc))\n","        print('Accuracy Drop : %.3f %%' % (100.*(before_prune_acc-acc)))\n","\n","\n","        print('--------------------------------------------------------------')\n","        model.train()\n","\n","  print(\"\\n\\n\")"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1650239522904,"user":{"displayName":"Akhil Reddy Anthireddy","userId":"13059027232826718756"},"user_tz":240},"id":"Tcc2xUNFKqAj"},"outputs":[],"source":["## Saving the model to a .pt file\n","torch.save(model.state_dict(),'/content/drive/My Drive/cs532_project2/resnet18_prune_50perc_iterative5_5.pt')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650239522905,"user":{"displayName":"Akhil Reddy Anthireddy","userId":"13059027232826718756"},"user_tz":240},"id":"r6usx8xkhgqA"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"prune_50perc_iterative_5_5.ipynb","provenance":[{"file_id":"1tcgtIjOb04VjGBucS8I63GRqTENBjN-q","timestamp":1650232973242},{"file_id":"1ljQqh8JbfUYt0qWSSGDL0uKML9clxFWs","timestamp":1650230261806}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2b205028157a4bdfa3793986c664bc41":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dd1d68ae2f14a5cab73f24ec3d0432a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2ad091de2ac41819417efebdec2b2ce","placeholder":"​","style":"IPY_MODEL_3b894f4bb158405189dcba5fd6243277","value":" 170499072/? [00:06&lt;00:00, 24313847.50it/s]"}},"2e8fbfb292744b82b3d6ca6837d16e82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d900d7d5e5641839e68781ca50df13a","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c848806b821d4f31902a41b325f9209b","value":170498071}},"3b894f4bb158405189dcba5fd6243277":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cb364e8a0664aa9866152d70547295a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79a1db2c0f1046f6bf4505b6b5643612","placeholder":"​","style":"IPY_MODEL_702d5bf86ccf4a7488bec7128851d1f0","value":""}},"59663be5028c4e65ae5a0d5fad90979c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cb364e8a0664aa9866152d70547295a","IPY_MODEL_2e8fbfb292744b82b3d6ca6837d16e82","IPY_MODEL_2dd1d68ae2f14a5cab73f24ec3d0432a"],"layout":"IPY_MODEL_2b205028157a4bdfa3793986c664bc41"}},"5d900d7d5e5641839e68781ca50df13a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"702d5bf86ccf4a7488bec7128851d1f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79a1db2c0f1046f6bf4505b6b5643612":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2ad091de2ac41819417efebdec2b2ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c848806b821d4f31902a41b325f9209b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
